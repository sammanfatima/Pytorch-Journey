{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMalsR3hYInWCn0JettWm+D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sammanfatima/Pytorch-Journey/blob/main/02_Pytorch_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Libraries**"
      ],
      "metadata": {
        "id": "m4nug4jEa9MG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. torch core pytorch library used for creating tensors(multi dim arrays) for storing large amount of data, initializing, math operations CPU/GPU support\n",
        "\n",
        "2. torch.nn helps you to create neural network easily, define models, create layers\n",
        "\n",
        "3. torch.optim to update weights during training\n",
        "\n",
        "4. torch.nn.functional(functionl API) for activation functions(relu, softmax) and other functions.\n",
        "\n",
        "5. from torch.utils.data to feed data into batches and shuffle it during training\n",
        "\n",
        "6. torchvision.datasets ready made datasets for images\n",
        "\n",
        "7. torchvision.transforms change image preparing your images so the network can understand them better\n",
        "like resize image, normalize img"
      ],
      "metadata": {
        "id": "TT6MZFvUcinE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLxjRfepanrx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create Fully Connected Network**"
      ],
      "metadata": {
        "id": "N3W-EWCRgr5h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* nn.Linear means fully connected newtork(dense)\n",
        "* input_size number of features ,50 no neurons (hidden unit)\n",
        "* num_classes no. of output neurons"
      ],
      "metadata": {
        "id": "l4P7pCYTkECd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Forward Propagation**"
      ],
      "metadata": {
        "id": "_eatdWeRoioJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* fc1 → hidden layer\n",
        "\n",
        "* ReLU → activation for hidden layer\n",
        "\n",
        "* fc2 → output layer, produces raw scores (logits)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NzQwu6YOoqPh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yK5Qgpp_ooBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NN(nn.Module): # inherit from pytorch's nn.module provide all tools to create layers, store weights\n",
        "  def __init__(self, input_size, num_classes): # constructor it automatically called when you create an instance of class\n",
        "    super(NN, self).__init__() # call the constructor of parent class\n",
        "    self.fc1 = nn.Linear(input_size, 50)\n",
        "    self.fc2 = nn.Linear(50, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "model = NN(784, 10)\n",
        "x = torch.rand(64, 784)\n",
        "print(model(x).shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEgrOMAag92f",
        "outputId": "6c095144-9b04-4752-8389-885add841e31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Set Device**"
      ],
      "metadata": {
        "id": "awawDroypYcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "wU50k9ZrpbQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hyperparameters**"
      ],
      "metadata": {
        "id": "tZ1KIwXgqBYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 784 # no of input features\n",
        "num_classes = 10 # no of output classes\n",
        "learning_rate = 0.01 # Controls how fast the model learns\n",
        "batch_size = 64 # Number of samples processed at one time\n",
        "num_epochs = 1 # Number of times the model sees the entire dataset"
      ],
      "metadata": {
        "id": "HWf-jShAsBln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Data**"
      ],
      "metadata": {
        "id": "4r55H4vINMSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train dataset\n",
        "train_dataset = datasets.MNIST(root= '/dataset', train=True, transform=transforms.ToTensor(), download=True)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size= batch_size, shuffle=True)\n",
        "\n",
        "# test dataset\n",
        "test_dataset = datasets.MNIST(root= '/dataset', train=False, transform=transforms.ToTensor(), download=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size= batch_size, shuffle=True)\n"
      ],
      "metadata": {
        "id": "YTNfzUvWNRV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Initialize Network**"
      ],
      "metadata": {
        "id": "WtR0QjfgPwXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = NN(input_size=input_size, num_classes=num_classes).to(device)"
      ],
      "metadata": {
        "id": "X9LeohmdP0rJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loss and Optimizer**"
      ],
      "metadata": {
        "id": "adCncLROQD0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss() #criterion is loss function which measures how wrong the output is\n",
        "# cross entropy used for classification problems\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate) #optimizer update weights so the loss become smaller\n",
        "# Adam is a smart optimizer that learns how to update weights efficiently"
      ],
      "metadata": {
        "id": "rRNY_IRjQCFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train Network**"
      ],
      "metadata": {
        "id": "9J6xPzLVVEti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  for batch_idx,(data, target) in enumerate(train_loader):# take small batches and then process see model batch by batch\n",
        "\n",
        "  # get data to cuda if possible\n",
        "    data = data.to(device=device) # batch input features\n",
        "    target = target.to(device=device) # batch correct labels\n",
        "\n",
        "    # get to correct shape\n",
        "    data = data.reshape(data.shape[0], -1)\n",
        "\n",
        "    #print(data.shape) # size and structure of the batch\n",
        "\n",
        "    # forward\n",
        "    scores = model(data)\n",
        "    loss = criterion(scores, target)\n",
        "\n",
        "    # backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # gradient descent or Adam step\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "RMDGUidPVItF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Check accuracy on train and test**"
      ],
      "metadata": {
        "id": "4vXJtZr8iATU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_accuracy(loader, model):\n",
        "  if loader.dataset.train:\n",
        "    print(\"Checking accuracy on training data\")\n",
        "  else:\n",
        "    print(\"Checking accuracy on test data\")\n",
        "\n",
        "  num_correct = 0\n",
        "  num_samples = 0\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for x, y in loader:\n",
        "      x = x.to(device=device)\n",
        "      y = y.to(device=device)\n",
        "\n",
        "      x = x.reshape(x.shape[0], -1)\n",
        "      scores = model(x)\n",
        "\n",
        "      scores = model(x)\n",
        "      _,predictions = scores.max(1)\n",
        "      num_correct += (predictions == y).sum()\n",
        "      num_samples += predictions.size(0)\n",
        "\n",
        "    print(f'Got {num_correct}/ {num_samples} with accuracy {float(num_correct)/float(num_samples)*100}')\n",
        "\n",
        "  model.train()\n",
        "\n",
        "\n",
        "check_accuracy(train_loader, model)\n",
        "check_accuracy(test_loader, model)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RKSHdKSiEwM",
        "outputId": "6451d01e-124e-42a6-f3ae-b60b40bfd6ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking accuracy on training data\n",
            "Got 57505/ 60000 with accuracy 95.84166666666667\n",
            "Checking accuracy on test data\n",
            "Got 9532/ 10000 with accuracy 95.32000000000001\n"
          ]
        }
      ]
    }
  ]
}